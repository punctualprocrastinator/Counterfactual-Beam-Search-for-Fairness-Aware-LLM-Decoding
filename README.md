
# Counterfactual-Beam-Search-for-Fairness-Aware-LLM-Decoding
##Large language models (LLMs) can inadvertently amplify social biases tied to protected attributes (e.g. religion, gender). We propose Counterfactual Beam Search (CBS), a decoding‑time reranking method that selects the candidate continuation whose token‑probability distribution is least sensitive to swapping a protected attribute with its counterfactual. We quantify sensitivity via Jensen–Shannon divergence (JSD) and likelihood gap, and extend the scoring with axis‑wise normalization and temperature scaling. We evaluate on two axes (religion: Muslim↔Hindu; gender pronouns: he↔she), comparing against two decoding‑time baselines—PPLM and Self‑Debias—and via both human annotation (N=3 raters, 150 prompts) and an LLM‑based “agentic” evaluator.
